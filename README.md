Reinforcement Learning
├── 1️⃣ Value-based Methods
│   ├── 1.1 Dynamic Programming (DP)
│   │   ├── Policy Evaluation
│   │   ├── Policy Iteration
│   │   └── Value Iteration
│   ├── 1.2 Monte Carlo Methods
│   ├── 1.3 Temporal Difference (TD) Methods
│   │   ├── TD(0)
│   │   ├── TD(n)
│   │   └── TD(λ)
│   ├── 1.4 Q-learning Family
│   │   ├── Q-learning (off-policy)
│   │   ├── SARSA (on-policy)
│   │   ├── Expected SARSA
│   │   └── Double Q-learning
│   └── 1.5 Deep Value Networks
│       ├── DQN
│       ├── Double DQN
│       ├── Dueling DQN
│       └── Rainbow DQN
│
├── 2️⃣ Policy-based Methods
│   ├── 2.1 REINFORCE (Vanilla Policy Gradient)
│   ├── 2.2 Baseline Methods
│   ├── 2.3 Actor-Critic Methods
│   │   ├── A2C / A3C
│   │   ├── DDPG (Continuous Action Space)
│   │   ├── TD3
│   │   └── SAC (Soft Actor-Critic)
│
├── 3️⃣ Model-based Methods
│   ├── Dyna-Q
│   ├── World Models
│   ├── MBPO (Model-Based Policy Optimization)
│
├── 4️⃣ Advanced / Modern RL
│   ├── PPO (Proximal Policy Optimization)
│   ├── TRPO (Trust Region Policy Optimization)
│   ├── GAE (Generalized Advantage Estimation)
│   └── DPO / GRPO (Reward Model Alignment)
│
├── 5️⃣ Multi-Agent & Hierarchical RL
│   ├── Multi-Agent Q-learning
│   ├── MADDPG
│   └── HRL (Options Framework)
│
└── 6️⃣ Application Domains
    ├── Game Environments: CartPole / LunarLander / Mario / Atari
    ├── Recommender Systems / Advertising Bidding Optimization
    ├── Robotics / Control
    ├── Finance / Trading Strategies
    └── Text Generation / LLM Fine-Tuning (RLHF / PPO)


强化学习框架
├── 1️⃣ 基础价值迭代类 (Value-based Methods)
│   ├── 1.1 动态规划 (Dynamic Programming)
│   │   ├── Policy Evaluation
│   │   ├── Policy Iteration
│   │   └── Value Iteration
│   ├── 1.2 蒙特卡罗方法 (Monte Carlo Methods)
│   ├── 1.3 时序差分法 (Temporal Difference, TD)
│   │   ├── TD(0)
│   │   ├── TD(n)
│   │   └── TD(λ)
│   ├── 1.4 Q-learning 系列
│   │   ├── Q-learning (off-policy)
│   │   ├── SARSA (on-policy)
│   │   ├── Expected SARSA
│   │   └── Double Q-learning
│   └── 1.5 深度价值网络 (Deep Value Methods)
│       ├── DQN
│       ├── Double DQN
│       ├── Dueling DQN
│       └── Rainbow DQN
│
├── 2️⃣ 策略梯度类 (Policy-based Methods)
│   ├── 2.1 纯策略梯度 (REINFORCE)
│   ├── 2.2 基线法 (Baseline)
│   ├── 2.3 Actor-Critic
│   │   ├── A2C / A3C
│   │   ├── DDPG (连续动作空间)
│   │   ├── TD3
│   │   └── SAC (Soft Actor-Critic)
│
├── 3️⃣ 模型驱动类 (Model-based Methods)
│   ├── Dyna-Q
│   ├── World Model
│   ├── MBPO (Model-Based Policy Optimization)
│
├── 4️⃣ 高级优化类 (Advanced / Modern RL)
│   ├── PPO (Proximal Policy Optimization)
│   ├── TRPO (Trust Region Policy Optimization)
│   ├── GAE (Generalized Advantage Estimation)
│   └── DPO / GRPO (Reward Model Alignment)
│
├── 5️⃣ 多智能体 / 层级类 (Multi-agent & Hierarchical RL)
│   ├── Multi-agent Q-learning
│   ├── MADDPG
│   └── HRL (Options Framework)
│
└── 6️⃣ 应用场景类 (Applications)
    ├── 游戏环境：CartPole / LunarLander / Mario / Atari
    ├── 推荐系统 / 广告出价优化
    ├── 机器人 / 控制
    ├── 金融 / 交易策略
    └── 文本生成 / LLM 调优 (RLHF / PPO)
